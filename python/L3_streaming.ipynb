{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483ab18e-f419-46ad-9bbe-171ffd05f983",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "<img src=\"./assets/LC_streaming.png\" width=\"400\">\n",
    "\n",
    "Streaming reduces the latency between generating data and the user receiving it.\n",
    "There are two types frequently used with Agents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0f22c-9724-46ce-baf3-60a2de701fb3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b76bab7-fa52-46f4-86bc-b157067e0168",
   "metadata": {},
   "source": [
    "Load and/or check for needed environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2fcfd93-0004-4ff1-9b60-0b21baf68c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY=****p0UA\n",
      "LANGSMITH_API_KEY=****77f2\n",
      "LANGSMITH_TRACING=true\n",
      "LANGSMITH_PROJECT=****ials\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(\"example.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166fc0b1-2322-4dd2-a358-89309fb9f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a26b4586-453a-4c10-9fae-4be3f4cb6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5\",\n",
    "    system_prompt=\"You are a full-stack comedian\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a907aa9-a608-47e2-92d4-6758a1728cb2",
   "metadata": {},
   "source": [
    "## No Steaming (invoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc384cf0-b208-4ab1-b7e2-f4b93dab08bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I told my database we needed to talk about our relationship—turns out it’s non-relational.\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke\"}]})\n",
    "print(result[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d7975-8d94-4d5e-8493-e68ac9fcedf9",
   "metadata": {},
   "source": [
    "## values\n",
    "You have seen this streaming mode in our examples so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30a2273-1dd3-47e8-a38e-05ed4b750000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me a Dad joke\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Why did the scarecrow win an award? Because he was outstanding in his field.\n"
     ]
    }
   ],
   "source": [
    "# Stream = values\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a Dad joke\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada88835-3c66-4241-b3d9-4f3d38390c86",
   "metadata": {},
   "source": [
    "## messages\n",
    "Messages stream data token by token - the lowest latency possible. This is perfect for interactive applications like chatbots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a9cc553-7357-4d36-b88d-25eaf7462cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The House Where Giggles Grow\n",
      "\n",
      "In our house the clock is ticklish; it giggles every hour,\n",
      "The toaster pops like fireworks—bread blossoms into flour.\n",
      "The dog tells knock-knock jokes and wags before the punch,\n",
      "The cat pretends it isn’t amused, but snickers in its lunch.\n",
      "\n",
      "Our spoons do synchronized swimming in a bowl of milky stars,\n",
      "The cereal makes tiny waves like traffic made of Mars.\n",
      "Dad says, “Lettuce romaine calm,” while chopping salad leaves,\n",
      "Mom rolls her eyes but laughs so hard she nearly drops the sieves.\n",
      "\n",
      "Grandma knits a scarf so long it loops around the moon,\n",
      "Grandpa hums a song that makes the cookies dance in tune.\n",
      "The baby blows a bubble big as any birthday wish,\n",
      "It pops into applause and sprinkles cheer on every dish.\n",
      "\n",
      "We search for missing socks like pirates chasing clues—\n",
      "They always hide in laundry land, disguised as socktopus.\n",
      "The broom sweeps up our giggles, but never keeps them long;\n",
      "They fly out with the sunshine and return as humming song.\n",
      "\n",
      "At dinner we say “peas and quiet”—but only for a beat,\n",
      "Then someone says, “Turnip the beet!” and tap-taps with their feet.\n",
      "We pass around the pasta-bilities and share the day’s bright tale,\n",
      "Where tiny troubles shrink to ants and kindness tips the scale.\n",
      "\n",
      "When bedtime drapes its velvet hat and yawns across the sky,\n",
      "The nightlight flips its pancake moon and whispers, “Don’t be shy.”\n",
      "We snuggle under blanket forts where cozy dreams can flow,\n",
      "And love—the best punchline of all—keeps giggles set to grow."
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Write me a family friendly poem.\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"{token.content}\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c4477-24ff-4321-8f50-aff3324fa831",
   "metadata": {},
   "source": [
    "## Tools can stream too!\n",
    "Streaming generally means delivering information to the user before the final result is ready. There are many cases where this is useful. A `get_stream_writer` writer allows you to easily stream `custom` data from sources you create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68179e6-d388-494a-b10d-109c230f6ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='e2e4ab54-58d0-4d46-994b-bd687cd3658d')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='e2e4ab54-58d0-4d46-994b-bd687cd3658d'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 132, 'total_tokens': 222, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cgxl2tRioO0WYIQmAytugKcwOZRal', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--af6f6191-b1ba-4909-9e65-6087c12974a7-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco, CA'}, 'id': 'call_fANhL7DKGPtfBUxUJ9kuRP9Z', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 90, 'total_tokens': 222, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}})]})\n",
      "('custom', 'Looking up data for city: San Francisco, CA')\n",
      "('custom', 'Acquired data for city: San Francisco, CA')\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='e2e4ab54-58d0-4d46-994b-bd687cd3658d'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 132, 'total_tokens': 222, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cgxl2tRioO0WYIQmAytugKcwOZRal', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--af6f6191-b1ba-4909-9e65-6087c12974a7-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco, CA'}, 'id': 'call_fANhL7DKGPtfBUxUJ9kuRP9Z', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 90, 'total_tokens': 222, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}), ToolMessage(content=\"It's always sunny in San Francisco, CA!\", name='get_weather', id='10fac9cf-95ce-41c5-8b16-5b8294982fd6', tool_call_id='call_fANhL7DKGPtfBUxUJ9kuRP9Z')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='e2e4ab54-58d0-4d46-994b-bd687cd3658d'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 132, 'total_tokens': 222, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cgxl2tRioO0WYIQmAytugKcwOZRal', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--af6f6191-b1ba-4909-9e65-6087c12974a7-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco, CA'}, 'id': 'call_fANhL7DKGPtfBUxUJ9kuRP9Z', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 90, 'total_tokens': 222, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}), ToolMessage(content=\"It's always sunny in San Francisco, CA!\", name='get_weather', id='10fac9cf-95ce-41c5-8b16-5b8294982fd6', tool_call_id='call_fANhL7DKGPtfBUxUJ9kuRP9Z'), AIMessage(content=\"It's always sunny in San Francisco, CA!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 172, 'total_tokens': 184, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cgxl7XXduDsh0nbJUpCyCYqGj3yOb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--7ab1fe75-df2a-45e3-98d2-4eba8cc6c438-0', usage_metadata={'input_tokens': 172, 'output_tokens': 12, 'total_tokens': 184, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]})\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    # stream any arbitrary data\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-mini\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d7ef47-e857-4e07-a233-888306e3e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('custom', 'Looking up data for city: San Francisco, CA')\n",
      "('custom', 'Acquired data for city: San Francisco, CA')\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3845c067-761f-46a0-817c-2cc42066ce9a",
   "metadata": {},
   "source": [
    "## Try different modes on your own!\n",
    "Modify the stream mode and the select to produce different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92943e4f-6c17-4fa3-ad00-f86464ba66f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],\n",
    "):\n",
    "    if chunk[0] == \"custom\":\n",
    "        print(chunk[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cec785-cd1e-4ec1-ba3b-0ea4cf4d804b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
